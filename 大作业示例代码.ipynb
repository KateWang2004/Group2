{"cells":[{"cell_type":"code","execution_count":1,"id":"61baace7-c441-4653-9ab3-372d574a79eb","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:39:48.073654Z","iopub.status.busy":"2025-04-28T09:39:48.073018Z","iopub.status.idle":"2025-04-28T09:40:00.861396Z","shell.execute_reply":"2025-04-28T09:40:00.860510Z","shell.execute_reply.started":"2025-04-28T09:39:48.073627Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch_geometric in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (2.6.1)\n","Requirement already satisfied: aiohttp in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (3.11.18)\n","Requirement already satisfied: fsspec in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: numpy in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (2.0.1)\n","Requirement already satisfied: psutil>=5.8.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (6.1.0)\n","Requirement already satisfied: pyparsing in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (3.2.0)\n","Requirement already satisfied: requests in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from aiohttp->torch_geometric) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from jinja2->torch_geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from requests->torch_geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from requests->torch_geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from requests->torch_geometric) (2025.4.26)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.11.0)\n","Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n","Requirement already satisfied: pyg_lib in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (0.4.0+pt25cu124)\n","Requirement already satisfied: torch_scatter in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (2.1.2)\n","Requirement already satisfied: torch_sparse in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (0.6.18+pt25cu124)\n","Requirement already satisfied: torch_cluster in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (1.6.3+pt25cu124)\n","Requirement already satisfied: torch_spline_conv in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (1.2.2+pt25cu124)\n","Requirement already satisfied: scipy in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from torch_sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages (from scipy->torch_sparse) (2.0.1)\n"]}],"source":["!pip install torch_geometric\n","!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"]},{"cell_type":"code","execution_count":2,"id":"da4d1b12","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:40:00.863430Z","iopub.status.busy":"2025-04-28T09:40:00.863174Z","iopub.status.idle":"2025-04-28T09:40:09.930450Z","shell.execute_reply":"2025-04-28T09:40:09.929884Z","shell.execute_reply.started":"2025-04-28T09:40:00.863409Z"},"trusted":true},"outputs":[],"source":["from copy import copy\n","import argparse\n","from tqdm.auto import tqdm\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import ModuleList, Linear, ParameterDict, Parameter\n","from torch_sparse import SparseTensor\n","from torch_geometric.utils import to_undirected\n","from torch_geometric.data import NeighborSampler\n","from torch_geometric.utils.hetero import group_hetero_graph\n","from torch_geometric.nn import MessagePassing\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"id":"8997e619","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:40:09.931546Z","iopub.status.busy":"2025-04-28T09:40:09.931099Z","iopub.status.idle":"2025-04-28T09:40:09.935193Z","shell.execute_reply":"2025-04-28T09:40:09.934412Z","shell.execute_reply.started":"2025-04-28T09:40:09.931520Z"},"trusted":true},"outputs":[],"source":["device = 'cuda:0'\n","num_layers = 2\n","hidden_channels = 64\n","dropout = 0.5\n","lr = 0.01\n","epoches = 3"]},{"cell_type":"code","execution_count":4,"id":"061baa31","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:40:09.936232Z","iopub.status.busy":"2025-04-28T09:40:09.936021Z","iopub.status.idle":"2025-04-28T09:40:14.490141Z","shell.execute_reply":"2025-04-28T09:40:14.489566Z","shell.execute_reply.started":"2025-04-28T09:40:09.936209Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_525731/1861813626.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load('data_masked.pt')\n"]},{"data":{"text/plain":["Data(\n","  num_nodes_dict={\n","    author=1134649,\n","    field_of_study=59965,\n","    institution=8740,\n","    paper=736389,\n","  },\n","  edge_index_dict={\n","    (author, affiliated_with, institution)=[2, 1043998],\n","    (author, writes, paper)=[2, 7145660],\n","    (paper, cites, paper)=[2, 5416271],\n","    (paper, has_topic, field_of_study)=[2, 7505078],\n","  },\n","  x_dict={ paper=[736389, 128] },\n","  node_year={ paper=[736389, 1] },\n","  edge_reltype={\n","    (author, affiliated_with, institution)=[1043998, 1],\n","    (author, writes, paper)=[7145660, 1],\n","    (paper, cites, paper)=[5416271, 1],\n","    (paper, has_topic, field_of_study)=[7505078, 1],\n","  },\n","  y_dict={ paper=[736389, 1] },\n","  num_classes=349,\n","  split={\n","    train={ paper=[629571] },\n","    valid={ paper=[64879] },\n","    test={ paper=[41939] },\n","  }\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = torch.load('data_masked.pt')\n","split_idx = data['split']\n","data.node_year_dict = None\n","data.edge_reltype_dict = None\n","data"]},{"cell_type":"code","execution_count":5,"id":"8db240da","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_525731/3624129115.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels = torch.tensor(y_dict['paper'], dtype=torch.long).squeeze().to(device)\n"]},{"name":"stdout","output_type":"stream","text":["tensor(-1, device='cuda:0') tensor(348, device='cuda:0')\n"]}],"source":["y_dict = data['y_dict']\n","labels = torch.tensor(y_dict['paper'], dtype=torch.long).squeeze().to(device) \n","print(labels.min(), labels.max())"]},{"cell_type":"code","execution_count":6,"id":"305b01ec","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:41:22.200556Z","iopub.status.busy":"2025-04-28T09:41:22.199945Z","iopub.status.idle":"2025-04-28T09:41:23.855147Z","shell.execute_reply":"2025-04-28T09:41:23.854401Z","shell.execute_reply.started":"2025-04-28T09:41:22.200529Z"},"trusted":true},"outputs":[],"source":["edge_index_dict = data.edge_index_dict\n","\n","# We need to add reverse edges to the heterogeneous graph.\n","r, c = edge_index_dict[('author', 'affiliated_with', 'institution')]\n","edge_index_dict[('institution', 'to', 'author')] = torch.stack([c, r])\n","\n","r, c = edge_index_dict[('author', 'writes', 'paper')]\n","edge_index_dict[('paper', 'to', 'author')] = torch.stack([c, r])\n","\n","r, c = edge_index_dict[('paper', 'has_topic', 'field_of_study')]\n","edge_index_dict[('field_of_study', 'to', 'paper')] = torch.stack([c, r])\n","\n","# Convert to undirected paper <-> paper relation.\n","edge_index = to_undirected(edge_index_dict[('paper', 'cites', 'paper')])\n","edge_index_dict[('paper', 'cites', 'paper')] = edge_index"]},{"cell_type":"code","execution_count":7,"id":"dfdc1534","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:42:24.967175Z","iopub.status.busy":"2025-04-28T09:42:24.966888Z","iopub.status.idle":"2025-04-28T09:42:25.894676Z","shell.execute_reply":"2025-04-28T09:42:25.894113Z","shell.execute_reply.started":"2025-04-28T09:42:24.967153Z"},"trusted":true},"outputs":[],"source":["out = group_hetero_graph(data.edge_index_dict, data.num_nodes_dict)\n","edge_index, edge_type, node_type, local_node_idx, local2global, key2int = out"]},{"cell_type":"code","execution_count":8,"id":"a0e207f1","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:44:19.659343Z","iopub.status.busy":"2025-04-28T09:44:19.658870Z","iopub.status.idle":"2025-04-28T09:44:19.663584Z","shell.execute_reply":"2025-04-28T09:44:19.662725Z","shell.execute_reply.started":"2025-04-28T09:44:19.659320Z"},"trusted":true},"outputs":[],"source":["x_dict = {}\n","for key, x in data.x_dict.items():\n","    x_dict[key2int[key]] = x\n","\n","num_nodes_dict = {}\n","for key, N in data.num_nodes_dict.items():\n","    num_nodes_dict[key2int[key]] = N"]},{"cell_type":"code","execution_count":9,"id":"b333611a","metadata":{"execution":{"iopub.execute_input":"2025-04-28T09:44:26.281208Z","iopub.status.busy":"2025-04-28T09:44:26.280931Z","iopub.status.idle":"2025-04-28T09:44:36.235045Z","shell.execute_reply":"2025-04-28T09:44:36.234520Z","shell.execute_reply.started":"2025-04-28T09:44:26.281176Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/data/wanglonghao_space/Softwares/anaconda3/envs/lyn5/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n","  warnings.warn(out)\n"]}],"source":["paper_idx = local2global['paper']\n","paper_train_idx = paper_idx[split_idx['train']['paper']]\n","\n","train_loader = NeighborSampler(edge_index, node_idx=paper_train_idx,\n","                               sizes=[25, 20], batch_size=1024, shuffle=True,\n","                               num_workers=4)"]},{"cell_type":"code","execution_count":10,"id":"1968950f","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:09.411648Z","iopub.status.busy":"2025-04-28T06:33:09.411083Z","iopub.status.idle":"2025-04-28T06:33:09.432898Z","shell.execute_reply":"2025-04-28T06:33:09.432136Z","shell.execute_reply.started":"2025-04-28T06:33:09.411625Z"},"trusted":true},"outputs":[],"source":["class RGCNConv(MessagePassing):\n","    def __init__(self, in_channels, out_channels, num_node_types,\n","                 num_edge_types):\n","        super(RGCNConv, self).__init__(aggr='mean')\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.num_node_types = num_node_types\n","        self.num_edge_types = num_edge_types\n","\n","        self.rel_lins = ModuleList([\n","            Linear(in_channels, out_channels, bias=False)\n","            for _ in range(num_edge_types)\n","        ])\n","\n","        self.root_lins = ModuleList([\n","            Linear(in_channels, out_channels, bias=True)\n","            for _ in range(num_node_types)\n","        ])\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for lin in self.rel_lins:\n","            lin.reset_parameters()\n","        for lin in self.root_lins:\n","            lin.reset_parameters()\n","\n","    def forward(self, x, edge_index, edge_type, target_node_type):\n","        x_src, x_target = x\n","\n","        out = x_target.new_zeros(x_target.size(0), self.out_channels)\n","\n","        for i in range(self.num_edge_types):\n","            mask = edge_type == i\n","            out.add_(self.propagate(edge_index[:, mask], x=x, edge_type=i))\n","\n","        for i in range(self.num_node_types):\n","            mask = target_node_type == i\n","            out[mask] += self.root_lins[i](x_target[mask])\n","\n","        return out\n","\n","    def message(self, x_j, edge_type: int):\n","        return self.rel_lins[edge_type](x_j)\n","\n","\n","class RGCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n","                 dropout, num_nodes_dict, x_types, num_edge_types):\n","        super(RGCN, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.hidden_channels = hidden_channels\n","        self.out_channels = out_channels\n","        self.num_layers = num_layers\n","        self.dropout = dropout\n","\n","        node_types = list(num_nodes_dict.keys())\n","        num_node_types = len(node_types)\n","\n","        self.num_node_types = num_node_types\n","        self.num_edge_types = num_edge_types\n","\n","        # Create embeddings for all node types that do not come with features.\n","        self.emb_dict = ParameterDict({\n","            f'{key}': Parameter(torch.Tensor(num_nodes_dict[key], in_channels))\n","            for key in set(node_types).difference(set(x_types))\n","        })\n","\n","        I, H, O = in_channels, hidden_channels, out_channels \n","\n","        self.convs = ModuleList()\n","        self.convs.append(RGCNConv(I, H, num_node_types, num_edge_types))\n","        for _ in range(num_layers - 2):\n","            self.convs.append(RGCNConv(H, H, num_node_types, num_edge_types))\n","        self.convs.append(RGCNConv(H, O, self.num_node_types, num_edge_types))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for emb in self.emb_dict.values():\n","            torch.nn.init.xavier_uniform_(emb)\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","\n","    def group_input(self, x_dict, node_type, local_node_idx, n_id=None):\n","        # Create global node feature matrix.\n","        if n_id is not None:\n","            node_type = node_type[n_id]\n","            local_node_idx = local_node_idx[n_id]\n","\n","        h = torch.zeros((node_type.size(0), self.in_channels),\n","                        device=node_type.device)\n","\n","        for key, x in x_dict.items():\n","            mask = node_type == key\n","            h[mask] = x[local_node_idx[mask]]\n","\n","        for key, emb in self.emb_dict.items():\n","            mask = node_type == int(key)\n","            h[mask] = emb[local_node_idx[mask]]\n","\n","        return h\n","\n","    def forward(self, n_id, x_dict, adjs, edge_type, node_type,\n","                local_node_idx):\n","\n","        x = self.group_input(x_dict, node_type, local_node_idx, n_id)\n","        node_type = node_type[n_id]\n","\n","        for i, (edge_index, e_id, size) in enumerate(adjs):\n","            x_target = x[:size[1]]\n","            node_type = node_type[:size[1]]\n","            conv = self.convs[i]\n","            x = conv((x, x_target), edge_index, edge_type[e_id], node_type)\n","            if i != self.num_layers - 1:\n","                x = F.relu(x)\n","                x = F.dropout(x, p=0.5, training=self.training)\n","\n","        return x.log_softmax(dim=-1)\n","\n","    def inference(self, x_dict, edge_index_dict, key2int):\n","        device = list(x_dict.values())[0].device\n","\n","        x_dict = copy(x_dict)\n","        for key, emb in self.emb_dict.items():\n","            x_dict[int(key)] = emb\n","\n","        adj_t_dict = {}\n","        for key, (row, col) in edge_index_dict.items():\n","            adj_t_dict[key] = SparseTensor(row=col, col=row).to(device)\n","\n","        for i, conv in enumerate(self.convs):\n","            out_dict = {}\n","\n","            for j, x in x_dict.items():\n","                out_dict[j] = conv.root_lins[j](x)\n","\n","            for keys, adj_t in adj_t_dict.items():\n","                src_key, target_key = keys[0], keys[-1]\n","                out = out_dict[key2int[target_key]]\n","                tmp = adj_t.matmul(x_dict[key2int[src_key]], reduce='mean')\n","                out.add_(conv.rel_lins[key2int[keys]](tmp))\n","\n","            if i != self.num_layers - 1:\n","                for j in range(self.num_node_types):\n","                    F.relu_(out_dict[j])\n","\n","            x_dict = out_dict\n","\n","        return x_dict"]},{"cell_type":"code","execution_count":11,"id":"3a2f4b86","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:15.732504Z","iopub.status.busy":"2025-04-28T06:33:15.732226Z","iopub.status.idle":"2025-04-28T06:33:17.509046Z","shell.execute_reply":"2025-04-28T06:33:17.508407Z","shell.execute_reply.started":"2025-04-28T06:33:15.732484Z"},"trusted":true},"outputs":[],"source":["model = RGCN(128, hidden_channels, data.num_classes, num_layers,\n","             dropout, num_nodes_dict, list(x_dict.keys()),\n","             len(edge_index_dict.keys())).to(device)\n","\n","y_global = node_type.new_full((node_type.size(0), 1), -1)\n","y_global[local2global['paper']] = data.y_dict['paper']\n","\n","x_dict = {k: v.to(device) for k, v in x_dict.items()}\n","edge_type = edge_type.to(device)\n","node_type = node_type.to(device)\n","local_node_idx = local_node_idx.to(device)\n","y_global = y_global.to(device)"]},{"cell_type":"code","execution_count":12,"id":"cac5d32f","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:19.950290Z","iopub.status.busy":"2025-04-28T06:33:19.949445Z","iopub.status.idle":"2025-04-28T06:33:19.957712Z","shell.execute_reply":"2025-04-28T06:33:19.956840Z","shell.execute_reply.started":"2025-04-28T06:33:19.950258Z"},"trusted":true},"outputs":[],"source":["def train(epoch):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    \n","    model.train()\n","\n","    pbar = tqdm(total=paper_train_idx.size(0))\n","    pbar.set_description(f'Epoch {epoch:02d}')\n","\n","    total_loss = 0\n","    for batch_size, n_id, adjs in train_loader:\n","        n_id = n_id.to(device)\n","        adjs = [adj.to(device) for adj in adjs]\n","        optimizer.zero_grad()\n","        out = model(n_id, x_dict, adjs, edge_type, node_type, local_node_idx)\n","        y = y_global[n_id][:batch_size].squeeze()\n","        loss = F.nll_loss(out, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * batch_size\n","        pbar.update(batch_size)\n","\n","    pbar.close()\n","\n","    loss = total_loss / paper_train_idx.size(0)\n","\n","    return loss"]},{"cell_type":"code","execution_count":13,"id":"807f0608","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:22.840699Z","iopub.status.busy":"2025-04-28T06:33:22.840378Z","iopub.status.idle":"2025-04-28T06:33:22.846296Z","shell.execute_reply":"2025-04-28T06:33:22.845494Z","shell.execute_reply.started":"2025-04-28T06:33:22.840677Z"},"trusted":true},"outputs":[],"source":["def calcuate_acc(y_true, y_pred):\n","    return torch.sum(y_true == y_pred) / y_true.shape[0]\n","@torch.no_grad()\n","def test():\n","    model.eval()\n","\n","    out = model.inference(x_dict, edge_index_dict, key2int)\n","    out = out[key2int['paper']]\n","\n","    y_pred = out.argmax(dim=-1, keepdim=True).cpu()\n","    y_true = data.y_dict['paper']\n","\n","    train_acc = calcuate_acc(y_true[split_idx['train']['paper']], y_pred[split_idx['train']['paper']])\n","    valid_acc = calcuate_acc(y_true[split_idx['valid']['paper']], y_pred[split_idx['valid']['paper']])\n","\n","    return train_acc, valid_acc, y_pred[split_idx['test']['paper']]"]},{"cell_type":"code","execution_count":14,"id":"80168d92","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:26.884066Z","iopub.status.busy":"2025-04-28T06:33:26.883319Z","iopub.status.idle":"2025-04-28T06:33:26.887507Z","shell.execute_reply":"2025-04-28T06:33:26.886974Z","shell.execute_reply.started":"2025-04-28T06:33:26.884047Z"},"trusted":true},"outputs":[],"source":["def save_pandas(root, y_pred):\n","    df = pd.DataFrame(y_pred, columns=['Predict'])\n","    df.insert(0, \"ID\", np.arange(len(df)))\n","    df.to_csv(root, index=False)"]},{"cell_type":"code","execution_count":16,"id":"9f6d093c","metadata":{"execution":{"iopub.execute_input":"2025-04-28T06:33:28.680650Z","iopub.status.busy":"2025-04-28T06:33:28.679969Z","iopub.status.idle":"2025-04-28T06:42:00.158040Z","shell.execute_reply":"2025-04-28T06:42:00.156951Z","shell.execute_reply.started":"2025-04-28T06:33:28.680628Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67d05e94d9a1412bb316c63a027a7fca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/629571 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 01, Loss: 1.7373, Train: 70.53%, Valid: 47.65%, \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10753314a37e4541a565957e7f534c2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/629571 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 02, Loss: 1.4478, Train: 77.21%, Valid: 47.36%, \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cc2365355194829a749952a17ec9cfc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/629571 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 03, Loss: 1.2701, Train: 81.10%, Valid: 46.59%, \n"]}],"source":["best_val_acc = 0\n","for epoch in range(1, 1 + epoches):\n","    loss = train(epoch)\n","    result = test()\n","    train_acc, valid_acc, y_pred = result\n","    print(f'Epoch: {epoch:02d}, '\n","            f'Loss: {loss:.4f}, '\n","            f'Train: {100 * train_acc:.2f}%, '\n","            f'Valid: {100 * valid_acc:.2f}%, ')\n","    if valid_acc >= best_val_acc:\n","        best_val_acc = valid_acc\n","        save_pandas('./submission.csv', y_pred)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":11896441,"sourceId":99462,"sourceType":"competition"}],"dockerImageVersionId":31011,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":5}
